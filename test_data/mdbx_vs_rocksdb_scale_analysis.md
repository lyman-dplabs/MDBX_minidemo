# MDBX vs RocksDB 跨数量级性能对比分析报告

## 执行摘要

本报告基于相同基准测试工作负载，对MDBX和RocksDB数据库在1亿和20亿两个数量级下的性能表现进行深度对比分析。测试采用32字节键长和32字节值长，涵盖四种测试场景：纯读操作、纯写操作、更新操作（读后写）以及混合读写操作。

具体的性能数据可以参阅本文档中的csv文件. 以及对应的md文件.

### 核心结论

**1亿级别**: MDBX的读性能和混合读写性能均优于RocksDB，能够满足预期需求
**20亿级别**: MDBX在所有维度的性能全面落后于RocksDB，存在明显的扩展性瓶颈

## 数据规模性能对比

### 1亿数据集性能表现

| 测试类型 | 优势数据库 | 性能提升 | 核心指标 |
|---------|-----------|---------|----------|
| 读取测试 | MDBX | 383.2% | 平均延迟: 1.59μs vs 7.69μs |
| 写入测试 | RocksDB | 99.8% | 平均延迟: 0.02μs vs 9.05μs |
| 更新测试 | MDBX | 136.2% | 平均延迟: 5.35μs vs 12.64μs |
| 混合测试 | MDBX | 410.0% | 平均延迟: 3.74μs vs 19.07μs |

### 20亿数据集性能表现

| 测试类型 | 优势数据库 | 性能提升 | 核心指标 |
|---------|-----------|---------|----------|
| 读取测试 | RocksDB | 81.4% | 平均延迟: 47.56μs vs 256.05μs |
| 写入测试 | RocksDB | 100.0% | 平均延迟: 0.01μs vs 361.23μs |
| 更新测试 | RocksDB | 87.0% | 平均延迟: 20.65μs vs 158.72μs |
| 混合测试 | RocksDB | 89.8% | 平均延迟: 26.80μs vs 261.96μs |

## 性能扩展性分析

### MDBX性能衰减分析

| 测试类型 | 1亿级延迟 | 20亿级延迟 | 性能衰减倍数 |
|---------|----------|----------|-------------|
| 读取 | 1.59μs | 256.05μs | 161x |
| 写入 | 9.05μs | 361.23μs | 40x |
| 更新 | 5.35μs | 158.72μs | 30x |
| 混合 | 3.74μs | 261.96μs | 70x |

### RocksDB性能衰减分析

| 测试类型 | 1亿级延迟 | 20亿级延迟 | 性能衰减倍数 |
|---------|----------|----------|-------------|
| 读取 | 7.69μs | 47.56μs | 6x |
| 写入 | 0.02μs | 0.01μs | 0.5x (性能提升) |
| 更新 | 12.64μs | 20.65μs | 1.6x |
| 混合 | 19.07μs | 26.80μs | 1.4x |

## 技术原因深度分析

### 1. 内存映射(mmap)瓶颈

**问题描述**: MDBX依赖单一的内存映射文件存储数据。在20亿数据量下，mmap文件可达数百GB。

**影响机制**:
- 随机访问模式下，内存页面命中率急剧下降
- 操作系统页面置换频繁，导致大量I/O等待
- 内存碎片化严重，影响缓存效率

**数据佐证**: MDBX读取性能从1.59μs衰减到256.05μs，衰减161倍

### 2. B+树结构开销

**问题描述**: 20亿数据导致B+树层级增加，节点分裂/合并操作频繁。

**影响机制**:
- 树高度增加，平均查找路径变长
- 节点分裂导致额外的I/O开销
- 内部节点缓存命中率下降

**数据佐证**: 更新操作性能衰减30倍，反映了树结构维护的高昂成本

### 3. Shadow Page模型局限性

**问题描述**: MDBX的写时复制(Copy-on-Write)机制在大规模随机写入下效率低下。

**影响机制**:
- 每次页面修改都需要完整页面复制
- 随机写入导致页面分布离散，放大复制开销
- 大量并发修改时，内存使用量激增

**数据佐证**: 写入性能衰减40倍，混合操作衰减70倍

### 4. 缺乏WAL机制

**问题描述**: MDBX没有预写日志，直接修改数据页面。

**影响机制**:
- 无法进行批量优化写入
- 事务提交成本高
- 无法有效进行写入排序和压缩

### 5. 参数配置问题

**问题描述**: 默认配置未针对大规模数据优化。

**可能改进**:
- 调整页面大小(pagesize)
- 优化缓存配置
- 调整事务参数

## 生产环境建议

### 数据规模评估策略

1. **阈值界定**: 基于测试结果，建议MDBX单表数据量不要膨胀到20亿级别.
2. **垂直分片**: 超过阈值的表应按时间、地理或业务维度拆分
3. **水平分片**: 考虑使用一致性哈希等算法进行数据分布

### 表设计最佳实践

1. **预估增长**: 设计时考虑3-5年数据增长预期
2. **访问模式**: 根据读写比例选择合适的存储引擎
3. **索引策略**: 避免过度索引，重点优化核心查询路径

### Reth项目优化借鉴

Reth (Rust Ethereum) 项目在大规模区块链数据存储方面提供了宝贵经验:

#### 核心优化策略

1. **排序写入**: 
   - 按键顺序批量写入
   - 减少随机I/O，提升吞吐量

2. **数据压缩**:
   - 使用LZ4/Snappy压缩算法
   - 在存储空间和CPU使用间取得平衡

3. **批量操作**:
   - 聚合小事务为大批次
   - 减少事务开销

#### 参考资源

```
GitHub: https://github.com/paradigmxyz/reth
核心模块: 
- crates/storage/
- crates/primitives/
- crates/db/

关键优化文档:
- Database Architecture: docs/design/database.md
- Performance Tuning: docs/performance/
```

---
*报告基于2025-09-17基准测试数据生成*
